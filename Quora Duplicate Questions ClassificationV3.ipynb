{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from utils.clean import text_to_wordlist\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from utils.tweaks import reduce_mem_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train = pd.read_csv('data/train_clean.csv')\n",
    "train = reduce_mem_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test = pd.read_csv('data/test_clean.csv')\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "      <td>2447329</td>\n",
       "      <td>3861609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "      <td>2686201</td>\n",
       "      <td>2627256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "      <td>3479610</td>\n",
       "      <td>3169183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "      <td>3738446</td>\n",
       "      <td>2245807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "      <td>4059625</td>\n",
       "      <td>320692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "3       3                        Which food not emulsifiers?   \n",
       "4       4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2     qid1     qid2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  2447329  3861609  \n",
       "1        How much cost does hair transplant require?  2686201  2627256  \n",
       "2                      What you send money to China?  3479610  3169183  \n",
       "3                                  What foods fibre?  3738446  2245807  \n",
       "4                     How their can I start reading?  4059625   320692  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = train.columns.tolist()[6:]\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[features_list], train['is_duplicate'], test_size=0.33, random_state=42,stratify=train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': 0.02,\n",
    "    'max_depth': 4,\n",
    "    }\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_test, 'test')]\n",
    "\n",
    "model = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_tree(model,num_trees=0)\n",
    "plt.rcParams['figure.figsize'] = [50, 100]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_duplicate'] = test.apply(lambda x: clf.predict(x[features_list]) ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['test_id','is_duplicate']].to_csv('data/1st_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROPOUT = 0.1\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)))\n",
    "\n",
    "def create_model():\n",
    "    # Taking the question1 as input and ceating a embedding for each question before feed it to neural network\n",
    "    q1 = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    embedding_q1 = layers.Lambda(UniversalEmbedding, output_shape=(512,))(q1)\n",
    "    # Taking the question2 and doing the same thing mentioned above, using the lambda function\n",
    "    q2 = layers.Input(shape=(1,), dtype=tf.string)\n",
    "    embedding_q2 = layers.Lambda(UniversalEmbedding, output_shape=(512,))(q2)\n",
    "\n",
    "    # Concatenating the both input layer\n",
    "    merged = layers.concatenate([embedding_q1, embedding_q2])\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    # Normalizing the input layer,applying dense and dropout  layer for fully connected model and to avoid overfitting \n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    merged = layers.Dense(200, activation='relu')(merged)\n",
    "    merged = layers.Dropout(DROPOUT)(merged)\n",
    "\n",
    "    # Using the Sigmoid as the activation function and binary crossentropy for binary classifcation as 0 or 1\n",
    "    merged = layers.BatchNormalization()(merged)\n",
    "    pred = layers.Dense(2, activation='sigmoid')(merged)\n",
    "    model = Model(inputs=[q1,q2], outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = train['question1']\n",
    "X2 = train['question2']\n",
    "y = train['is_duplicate']\n",
    "# Using the sklearn to split data in question1 and question2 train and test in the ration 80-20 %\n",
    "X1_train, X1_test,X2_train, X2_test, y_train, y_test = train_test_split(X1, X2, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_q1 = X1_train.tolist()\n",
    "train_q1 = np.array(train_q1, dtype=object)[:, np.newaxis]\n",
    "train_q2 = X2_train.tolist()\n",
    "train_q2 = np.array(train_q2, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_labels = np.asarray(pd.get_dummies(y_train), dtype = np.int8)\n",
    "\n",
    "test_q1 = X1_test.tolist()\n",
    "test_q1 = np.array(test_q1, dtype=object)[:, np.newaxis]\n",
    "test_q2 = X2_test.tolist()\n",
    "test_q2 = np.array(test_q2, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test_labels = np.asarray(pd.get_dummies(y_test), dtype = np.int8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 512)          0           input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 512)          0           input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 200)          205000      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 200)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 200)          800         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 200)          40200       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 200)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 200)          800         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 200)          40200       batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 200)          0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 200)          800         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 200)          40200       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 200)          0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 200)          800         dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            402         batch_normalization_12[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 329,202\n",
      "Trainable params: 327,602\n",
      "Non-trainable params: 1,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Creating the tensorflow session to train the model and save checkpoint after every epoch.\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "\n",
    "    filepath=\"models/model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "    callbacks_list = [checkpoint]\n",
    "    history = nn_model.fit([train_q1, train_q2], \n",
    "            train_labels,\n",
    "            validation_data=([test_q1, test_q2], test_labels),\n",
    "            epochs=10,\n",
    "            batch_size=512, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type Question 1 here --> how are you\n",
      "Type Question 2 here --> are you alright\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----FINAL RESULT----\n",
      "****Questions are not Similar****\n"
     ]
    }
   ],
   "source": [
    "q1 = input(\"Type Question 1 here -->\")\n",
    "q2 = input(\"Type Question 2 here -->\") \n",
    "q1 = np.array([[q1],[q1]])\n",
    "q2 = np.array([[q2],[q2]])\n",
    "# Using the same tensorflow session for embedding the test string\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    # Loading the save weights\n",
    "    nn_model.load_weights('models/model-01-0.50.hdf5')  \n",
    "    # Predicting the similarity between the two input questions \n",
    "    predicts = nn_model.predict([q1, q2], verbose=0)\n",
    "    predict_logits = predicts.argmax(axis=1)\n",
    "    print(\"----FINAL RESULT----\")\n",
    "    if(predict_logits[0] == 1):\n",
    "        print(\"****Questions are Similar****\")\n",
    "    else:\n",
    "        print(\"****Questions are not Similar****\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
